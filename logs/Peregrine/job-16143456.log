2020-12-13 19:16:55.199304: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
--------------------------------------------------------------------------
[[62227,1],0]: A high-performance Open MPI point-to-point messaging module
was unable to find any relevant network interfaces:

Module: OpenFabrics (openib)
  Host: pg-gpu10

Another transport will be used instead, although this may result in
lower performance.

NOTE: You can disable this warning by setting the MCA parameter
btl_base_warn_component_unused to 0.
--------------------------------------------------------------------------
12/13/2020 19:17:27 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False
12/13/2020 19:17:27 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='/tmp/mlm_SemEval', overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec13_19-17-27_pg-gpu10', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='/tmp/mlm_SemEval', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)
Downloading:   0%|          | 0.00/1.10k [00:00<?, ?B/s]Downloading: 2.57kB [00:00, 1.18MB/s]                   
Using custom data configuration default
Traceback (most recent call last):
  File "run_mlm.py", line 392, in <module>
    main()
  File "run_mlm.py", line 211, in main
    datasets = load_dataset(extension, data_files=data_files)
  File "/home/s2964007/.local/lib/python3.7/site-packages/datasets/load.py", line 603, in load_dataset
    **config_kwargs,
  File "/home/s2964007/.local/lib/python3.7/site-packages/datasets/builder.py", line 155, in __init__
    **config_kwargs,
  File "/home/s2964007/.local/lib/python3.7/site-packages/datasets/builder.py", line 305, in _create_builder_config
    m.update(str(os.path.getmtime(data_file)))
  File "/software/software/Python/3.7.4-GCCcore-8.3.0/lib/python3.7/genericpath.py", line 55, in getmtime
    return os.stat(filename).st_mtime
FileNotFoundError: [Errno 2] No such file or directory: '/SemEval data/finetuning_train.txt'


###############################################################################
Peregrine Cluster
Job 16143456 for user 's2964007'
Finished at: Sun Dec 13 19:17:30 CET 2020

Job details:
============

Job ID              : 16143456
Name                : BERT_Finetuning
User                : s2964007
Partition           : gpu
Nodes               : pg-gpu10
Number of Nodes     : 1
Cores               : 12
State               : FAILED
Submit              : 2020-12-13T19:16:40
Start               : 2020-12-13T19:16:43
End                 : 2020-12-13T19:17:30
Reserved walltime   : 01:00:00
Used walltime       : 00:00:47
Used CPU time       : 00:00:06 (efficiency:  1.12%)
% User (Computation): 78.36%
% System (I/O)      : 21.63%
Mem reserved        : 4000M/node
Max Mem used        : 220.45M (pg-gpu10)
Max Disk Write      : 0.00  (pg-gpu10)
Max Disk Read       : 40.96K (pg-gpu10)
Average GPU usage   : No GPU metrics available (pg-gpu10)


Acknowledgements:
=================

Please see this page for information about acknowledging Peregrine in your publications:

https://wiki.hpc.rug.nl/peregrine/additional_information/scientific_output

################################################################################
